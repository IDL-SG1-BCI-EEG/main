{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IDL-SG1-BCI-EEG/main/blob/yuhsun/IDL_BCI_EEG_EDA_STD_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **IDL Project: Predicting BCI_EEG signals using Deep Learning**"
      ],
      "metadata": {
        "id": "gKmE7gECKOzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb --quiet\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchsummary import summary\n",
        "import torchvision\n",
        "\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import wandb\n",
        "import matplotlib.pyplot as plt\n",
        "import multiprocessing as mp\n",
        "import scipy\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Num_Workers: {mp.cpu_count()}')\n",
        "print(\"Device: \", DEVICE)"
      ],
      "metadata": {
        "id": "kVGiRP5bYDBI",
        "outputId": "99e1e6d0-b60c-4775-cc8c-cf165ab18516",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.7/201.7 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Num_Workers: 2\n",
            "Device:  cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "MaPGcjXcREnk",
        "outputId": "deeaeba6-8996-4d8b-c489-5655d64be28e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BCI_EEG_data.zip    100%[===================>]   4.84G  20.2MB/s    in 4m 20s  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nOriginal Data From:\\n *https://figshare.com/articles/online_resource/Shared_data_for_exploring_training_effect_in_42_human_subjects_using_a_noninvasive_sensorimotor_rhythm-based_online_BCI/7959572*\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Get BCI_EEG Data \n",
        "!mkdir /content/bci_data\n",
        "!wget -q https://cmu.box.com/shared/static/dje4whisfwszhe2vvfphvahzr563kp2x.zip --content-disposition --show-progress\n",
        "!unzip -qo 'BCI_EEG_data.zip' -d '/content/bci_data'\n",
        "\n",
        "\"\"\"\n",
        "Original Data From:\n",
        " *https://figshare.com/articles/online_resource/Shared_data_for_exploring_training_effect_in_42_human_subjects_using_a_noninvasive_sensorimotor_rhythm-based_online_BCI/7959572*\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EDA**\n",
        "\n",
        "---\n",
        "...Each file includes the online results from the BCI experimentation for each run (saved in a cell variable ‘BCI_UseResults’), key parameters for the experiment (saved in a structure ‘Experiment_Parm’), key parameters for the state of the raw EEG signal (saved in a structure ‘Experimental_states’), and the raw EEG signal (saved in a variable ‘output_data’).\n",
        "\n",
        "The raw EEG signals for experiments one and two are composed of 62 channels of EEG data with a sampling frequency of 100Hz, while data for experiment three contains 64 channels of EEG sampled at 128Hz..."
      ],
      "metadata": {
        "id": "gNyTyf4vJxdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'epochs'        : 20,\n",
        "    'batch_size'    : 32,\n",
        "    'lr'            : 5e-4, # 0.1 for SGD, 5e-4 for adamW\n",
        "    'patience'      : 2,\n",
        "    'lr_decay'      : 0.1,\n",
        "    'weight_decay'  : 0.001,\n",
        "    'momentum'      : 0.9,\n",
        "    'nesterov'      : True,\n",
        "    'drop_rate'     : 0.25,\n",
        "    'label_smooth'  : 0.1,\n",
        "    'drop_path'     : 0.1\n",
        "}"
      ],
      "metadata": {
        "id": "r5bbqCLYAmAg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SubjectDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, root, subject = 1, mode = 'train'):\n",
        "        \n",
        "        self.eegs, self.results = [], []\n",
        "        for experiment in [\"Exp1\",\"Exp2\"]:\n",
        "            dir = root + '/' + experiment\n",
        "            for session in os.listdir(dir):\n",
        "                should_load = f'Subj{subject}_' in session\n",
        "                if mode == 'train':\n",
        "                    should_load = not should_load\n",
        "                if should_load:\n",
        "                    # Load a single mat file\n",
        "                    mat = scipy.io.loadmat(dir+'/'+session)\n",
        "                    # Get raw EEG data in one session\n",
        "                    session_eeg = mat['output_data']   \n",
        "                    # Get target code in one session\n",
        "                    exp_states = dict()\n",
        "                    for _ in mat['Experimental_states']:\n",
        "                        for wrapper in _:\n",
        "                            fieldnames = wrapper.dtype.names\n",
        "                            for idx, val in enumerate(wrapper):\n",
        "                                exp_states[f'{fieldnames[idx]}'] = val.flatten()\n",
        "                    session_targetCode = exp_states['TargetCode']-1\n",
        "                    '''\n",
        "                    TODO: The different effective length of 3 sessions will cause problems for data loader.\n",
        "                    --> for now, we use a fix number 100 as the effective duration\n",
        "                    --> If this impacts the model performance, we can try pad_pack_sequence\n",
        "                    '''\n",
        "                    \n",
        "                    # Remove useless data\n",
        "                    trial_start_index = np.nonzero(np.diff(session_targetCode))[0][::2]+1\n",
        "                    trial_start_end_index = np.nonzero(np.diff(session_targetCode))[0]+1\n",
        "\n",
        "                    # Split continuous eeg data to trials\n",
        "                    eeg_split_trials = np.split(session_eeg,trial_start_end_index)[1::2]\n",
        "                    \n",
        "                    # Motor imgination starts 2s after the target shows up. Plus 0.1s for reactions time\n",
        "                    effective_start = 210\n",
        "                    \n",
        "                    # The target freezes for 1s after hitting the target, signals in this 1s is useless.\n",
        "                    # Use the min duration time - 1s as the effective end time. \n",
        "                    # Different sessions have different min duration time\n",
        "                    # min_trial_duration = np.amin(np.diff(trial_start_end_index)[::2])\n",
        "                    # effective_end = min_trial_duration - 100\n",
        "                    \n",
        "                    # Update: for now, we use a fix number 100 as the effective duration\n",
        "                    effective_end = effective_start + 100\n",
        "                    \n",
        "                    effective_eeg = []\n",
        "                    for eeg in eeg_split_trials:\n",
        "                        # Exponential standardization\n",
        "                        eeg_standardized = np.zeros_like(eeg[effective_start:effective_end,:])\n",
        "                        mean = 0\n",
        "                        var = 0\n",
        "                        alpha = 0.999\n",
        "                        for t in range(eeg[effective_start:effective_end,:].shape[0]):\n",
        "                            mean = alpha * mean + (1 - alpha) * eeg[effective_start:effective_end,:][t]\n",
        "                            var = alpha * var + (1 - alpha) * (eeg[effective_start:effective_end,:][t] - mean) ** 2\n",
        "                            eeg_standardized[t] = (eeg[effective_start:effective_end,:][t] - mean) / np.sqrt(var + 1e-8)\n",
        "                        effective_eeg.append(eeg_standardized)\n",
        "                    \n",
        "                    # Remove useless target code\n",
        "                    session_targetCode = session_targetCode[trial_start_index]\n",
        "                    \n",
        "                    # Add the session data into the array\n",
        "                    self.eegs += (effective_eeg)\n",
        "                    self.results.append(session_targetCode)\n",
        "        \n",
        "        # Concatenate results\n",
        "        self.results = np.concatenate(self.results)    \n",
        "        self.length = len(self.results)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, ind):\n",
        "        eegs = np.array(self.eegs[ind]) # extra [] to make an additional dimension for channel #REMOVED\n",
        "        eegs = torch.FloatTensor(eegs)\n",
        "        results = torch.tensor(self.results[ind])\n",
        "        return eegs, results\n",
        "\n",
        "    '''\n",
        "    TODO: Discuss if we need batch-wise operations.\n",
        "    '''\n",
        "    # def collate_fn(batch):\n",
        "    #     return batch"
      ],
      "metadata": {
        "id": "QYe2eAEp2fMA"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del train_dataset, test_dataset, train_loader, test_loader"
      ],
      "metadata": {
        "id": "9q0Y9CS9EtGp"
      },
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RK2P_s-IEz_r",
        "outputId": "f2887114-b18e-4417-f40d-7db7663426ce"
      },
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test of dataset and data loader\n",
        "root = '/content/bci_data'\n",
        "train_dataset = SubjectDataset(root, subject=1, mode = 'train')\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = train_dataset, \n",
        "    num_workers = 2,\n",
        "    batch_size  = config['batch_size'], \n",
        "    pin_memory  = True,\n",
        "    shuffle     = True,\n",
        "    # collate_fn  = AudioDataset.collate_fn\n",
        ")\n",
        "\n",
        "test_dataset = SubjectDataset(root, subject=1, mode = 'test')\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = test_dataset, \n",
        "    num_workers = 2,\n",
        "    batch_size  = config['batch_size'], \n",
        "    pin_memory  = True,\n",
        "    shuffle     = False,\n",
        "    # collate_fn  = AudioDataset.collate_fn\n",
        ")"
      ],
      "metadata": {
        "id": "CTgjdYup3BwD"
      },
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"No. of data         : \", train_dataset.__len__())\n",
        "print(\"No. of test data    : \", test_dataset.__len__())\n",
        "print(\"Shape of data       : \", train_dataset[0][0].shape)\n",
        "\n",
        "print(\"Train batches       : \", train_loader.__len__())\n",
        "print(\"Test batches        : \", test_loader.__len__())\n",
        "\n",
        "# Test of dataset and data loader\n",
        "for x, y in train_loader:\n",
        "    print(x.shape, y.shape)\n",
        "    xt, yt = x, y\n",
        "    break\n",
        "print(xt.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4y_Ya8W3Whr",
        "outputId": "21aee0e8-5754-4b00-8b59-052c8c62d98e"
      },
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of data         :  9945\n",
            "No. of test data    :  375\n",
            "Shape of data       :  torch.Size([100, 62])\n",
            "Train batches       :  311\n",
            "Test batches        :  12\n",
            "torch.Size([32, 100, 62]) torch.Size([32])\n",
            "torch.Size([32, 100, 62])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model:CustomNet (Conv1d embedder - Transformer Encoder - Classification Head)"
      ],
      "metadata": {
        "id": "nPMeAQmf3iNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomNet(nn.Module):\n",
        "    def __init__(self, in_channels=62, hid_dim=6, n_classes=2, n_layers=5,dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.embedder = nn.Sequential(#PermuteBlock(),\n",
        "            nn.Linear(in_channels, in_channels*2),\n",
        "            nn.LayerNorm(in_channels*2), torch.nn.GELU(),\n",
        "            nn.Linear(in_channels*2, in_channels*4),\n",
        "            nn.LayerNorm(in_channels*4), torch.nn.GELU(),\n",
        "           )#PermuteBlock())\n",
        "\n",
        "        self.rnn = nn.LSTM(in_channels*4, hid_dim, num_layers=n_layers, batch_first=True,\n",
        "                           dropout=dropout)\n",
        "        self.class_head = nn.Sequential(\n",
        "            nn.Linear(hid_dim, n_classes),\n",
        "        )\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight, gain=1)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedder(x)\n",
        "        x, _ = self.rnn(x)\n",
        "        x = self.class_head(x)\n",
        "        return x[:,-1,:]"
      ],
      "metadata": {
        "id": "E12pR3kG3wop"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomNet(in_channels=62, hid_dim=4, n_classes=2,n_layers=4, dropout=0.45).to(DEVICE)\n",
        "print(model)\n",
        "# xt = xt.cuda()\n",
        "# summary(model, xt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1CE_bEZAGdG",
        "outputId": "bfd9a397-8743-4331-b3b9-ce655624cc5d"
      },
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CustomNet(\n",
            "  (embedder): Sequential(\n",
            "    (0): Linear(in_features=62, out_features=124, bias=True)\n",
            "    (1): LayerNorm((124,), eps=1e-05, elementwise_affine=True)\n",
            "    (2): GELU(approximate='none')\n",
            "    (3): Linear(in_features=124, out_features=248, bias=True)\n",
            "    (4): LayerNorm((248,), eps=1e-05, elementwise_affine=True)\n",
            "    (5): GELU(approximate='none')\n",
            "  )\n",
            "  (rnn): LSTM(248, 4, num_layers=4, batch_first=True, dropout=0.45)\n",
            "  (class_head): Sequential(\n",
            "    (0): Linear(in_features=4, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=config['lr'], momentum=config['momentum'], weight_decay=config['weight_decay'])\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=config['lr']) #, weight_decay=0.001)\n",
        "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(patience = 5)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "         optimizer=optimizer,\n",
        "         T_max = config['epochs'],\n",
        "         eta_min=1e-6,\n",
        "         verbose=True,\n",
        " )\n",
        "scaler = torch.cuda.amp.GradScaler()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBqIEBdEACK4",
        "outputId": "33310d2d-c8d4-49f8-c98f-d90d88c1ebfa"
      },
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adjusting learning rate of group 0 to 5.0000e-04.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, optimizer, criterion):\n",
        "    \n",
        "    model.train()\n",
        "\n",
        "    # Progress Bar \n",
        "    batch_bar   = tqdm(total=len(dataloader), dynamic_ncols=True, leave=False, position=0, desc='Train', ncols=5) \n",
        "\n",
        "    num_correct = 0\n",
        "    total_loss  = 0\n",
        "\n",
        "    for i, (x, y) in enumerate(dataloader):\n",
        "        \n",
        "        optimizer.zero_grad() # Zero gradients\n",
        "\n",
        "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "        \n",
        "        with torch.cuda.amp.autocast(): # This implements mixed precision. Thats it! \n",
        "            outputs = model(x)\n",
        "            loss    = criterion(outputs, y)\n",
        "\n",
        "        # Update no. of correct predictions & loss as we iterate\n",
        "        num_correct     += int((torch.argmax(outputs, axis=1) == y).sum())\n",
        "        total_loss      += float(loss.item())\n",
        "\n",
        "        # tqdm lets you add some details so you can monitor training as you train.\n",
        "        batch_bar.set_postfix(\n",
        "            acc         = \"{:.04f}%\".format(100 * num_correct / (config['batch_size']*(i + 1))),\n",
        "            loss        = \"{:.04f}\".format(float(total_loss / (i + 1))),\n",
        "            num_correct = num_correct,\n",
        "            lr          = \"{:.04f}\".format(float(optimizer.param_groups[0]['lr']))\n",
        "        )\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # scaler.scale(loss).backward() # This is a replacement for loss.backward()\n",
        "        # scaler.step(optimizer) # This is a replacement for optimizer.step()\n",
        "        # scaler.update() \n",
        "\n",
        "        # TODO? Depending on your choice of scheduler,\n",
        "        # You may want to call some schdulers inside the train function. What are these?\n",
        "      \n",
        "        batch_bar.update() # Update tqdm bar\n",
        "\n",
        "        del x, y, outputs, loss\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    batch_bar.close() # You need this to close the tqdm bar\n",
        "\n",
        "    acc         = 100 * num_correct / (config['batch_size']* len(dataloader))\n",
        "    total_loss  = float(total_loss / len(dataloader))\n",
        "\n",
        "    return acc, total_loss"
      ],
      "metadata": {
        "id": "udHHcoc3CJMW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, dataloader, criterion):\n",
        "  \n",
        "    model.eval()\n",
        "    batch_bar = tqdm(total=len(dataloader), dynamic_ncols=True, position=0, leave=False, desc='Val', ncols=5)\n",
        "\n",
        "    num_correct = 0.0\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i, (x, y) in enumerate(dataloader):\n",
        "        \n",
        "        # Move images to device\n",
        "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "        \n",
        "        # Get model outputs\n",
        "        with torch.inference_mode():\n",
        "            outputs = model(x)\n",
        "            loss = criterion(outputs, y)\n",
        "\n",
        "        num_correct += int((torch.argmax(outputs, axis=1) == y).sum())\n",
        "        total_loss += float(loss.item())\n",
        "\n",
        "        batch_bar.set_postfix(\n",
        "            acc=\"{:.04f}%\".format(100 * num_correct / (config['batch_size']*(i + 1))),\n",
        "            loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
        "            num_correct=num_correct)\n",
        "\n",
        "        batch_bar.update()\n",
        "        del x, y, outputs, loss\n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "    batch_bar.close()\n",
        "    acc = 100 * num_correct / (config['batch_size']* len(dataloader))\n",
        "    total_loss = float(total_loss / len(dataloader))\n",
        "    return acc, total_loss"
      ],
      "metadata": {
        "id": "UQ372GHOCOMn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_valacc = 0.0\n",
        "\n",
        "val_list = []\n",
        "\n",
        "for epoch in range(config['epochs']):\n",
        "    curr_lr = float(optimizer.param_groups[0]['lr'])\n",
        "    train_acc, train_loss = train(model, train_loader, optimizer, criterion)\n",
        "    \n",
        "    print(\"\\nEpoch {}/{}: \\nTrain Acc {:.04f}%\\t Train Loss {:.04f}\\t Learning Rate {:.04f}\".format(\n",
        "        epoch + 1,\n",
        "        config['epochs'],\n",
        "        train_acc,\n",
        "        train_loss,\n",
        "        curr_lr))\n",
        "    \n",
        "    val_acc, val_loss = validate(model, test_loader, criterion)\n",
        "    print(\"Val Acc {:.04f}%\\t Val Loss {:.04f}\".format(val_acc, val_loss))\n",
        "\n",
        "    val_list.append(val_acc)\n",
        "    \n",
        "    # wandb.log({\"train_loss\":train_loss, 'train_Acc': train_acc, 'validation_Acc':val_acc, \n",
        "    #            'validation_loss': val_loss, \"learning_Rate\": curr_lr})\n",
        "    \n",
        "    # If you are using a scheduler in your train function within your iteration loop, you may want to log\n",
        "    # your learning rate differently\n",
        "    # scheduler.step(val_loss)\n",
        "    scheduler.step()\n",
        "\n",
        "    #Save model in drive location if val_acc is better than best recorded val_acc\n",
        "    # if val_acc >= best_valacc:\n",
        "    #   #path = os.path.join(root, model_directory, 'checkpoint' + '.pth')\n",
        "    #   print(\"Saving model\")\n",
        "    #   torch.save({'model_state_dict':arcfacemodel.model.state_dict(),\n",
        "    #               'optimizer_state_dict':optimizer.state_dict(),\n",
        "    #               'scheduler_state_dict':scheduler.state_dict(),\n",
        "    #               'val_acc': val_acc, \n",
        "    #               'epoch': epoch}, './checkpoint.pth')\n",
        "    #   best_valacc = val_acc\n",
        "    #   wandb.save('checkpoint.pth')\n",
        "      # You may find it interesting to exlplore Wandb Artifcats to version your models\n",
        "# run.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npGoxEOyCPUV",
        "outputId": "182da160-1940-4fd7-c322-408004cc869b"
      },
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/20: \n",
            "Train Acc 69.4634%\t Train Loss 0.6452\t Learning Rate 0.0005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc 72.6562%\t Val Loss 0.5710\n",
            "Adjusting learning rate of group 0 to 4.9693e-04.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2/20: \n",
            "Train Acc 73.3923%\t Train Loss 0.5698\t Learning Rate 0.0005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc 71.8750%\t Val Loss 0.5497\n",
            "Adjusting learning rate of group 0 to 4.8779e-04.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3/20: \n",
            "Train Acc 73.7842%\t Train Loss 0.5580\t Learning Rate 0.0005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc 71.0938%\t Val Loss 0.5710\n",
            "Adjusting learning rate of group 0 to 4.7281e-04.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4/20: \n",
            "Train Acc 74.4273%\t Train Loss 0.5479\t Learning Rate 0.0005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc 71.0938%\t Val Loss 0.5377\n",
            "Adjusting learning rate of group 0 to 4.5235e-04.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5/20: \n",
            "Train Acc 74.6785%\t Train Loss 0.5385\t Learning Rate 0.0005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc 73.1771%\t Val Loss 0.5255\n",
            "Adjusting learning rate of group 0 to 4.2692e-04.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6/20: \n",
            "Train Acc 74.9699%\t Train Loss 0.5321\t Learning Rate 0.0004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc 76.8229%\t Val Loss 0.4977\n",
            "Adjusting learning rate of group 0 to 3.9715e-04.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7/20: \n",
            "Train Acc 75.7938%\t Train Loss 0.5237\t Learning Rate 0.0004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc 77.3438%\t Val Loss 0.4871\n",
            "Adjusting learning rate of group 0 to 3.6377e-04.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8/20: \n",
            "Train Acc 76.0048%\t Train Loss 0.5212\t Learning Rate 0.0004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc 75.2604%\t Val Loss 0.4980\n",
            "Adjusting learning rate of group 0 to 3.2760e-04.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 9/20: \n",
            "Train Acc 76.1656%\t Train Loss 0.5162\t Learning Rate 0.0003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc 75.0000%\t Val Loss 0.5065\n",
            "Adjusting learning rate of group 0 to 2.8953e-04.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10/20: \n",
            "Train Acc 76.7283%\t Train Loss 0.5108\t Learning Rate 0.0003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc 76.0417%\t Val Loss 0.4929\n",
            "Adjusting learning rate of group 0 to 2.5050e-04.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 11/20: \n",
            "Train Acc 77.1503%\t Train Loss 0.5071\t Learning Rate 0.0003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc 75.7812%\t Val Loss 0.4975\n",
            "Adjusting learning rate of group 0 to 2.1147e-04.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 12/20: \n",
            "Train Acc 77.2609%\t Train Loss 0.5023\t Learning Rate 0.0002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc 76.8229%\t Val Loss 0.5075\n",
            "Adjusting learning rate of group 0 to 1.7340e-04.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 13/20: \n",
            "Train Acc 77.4216%\t Train Loss 0.4998\t Learning Rate 0.0002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc 76.3021%\t Val Loss 0.5068\n",
            "Adjusting learning rate of group 0 to 1.3723e-04.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 14/20: \n",
            "Train Acc 77.5221%\t Train Loss 0.4940\t Learning Rate 0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc 75.5208%\t Val Loss 0.4995\n",
            "Adjusting learning rate of group 0 to 1.0385e-04.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 15/20: \n",
            "Train Acc 78.4566%\t Train Loss 0.4887\t Learning Rate 0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc 75.2604%\t Val Loss 0.5003\n",
            "Adjusting learning rate of group 0 to 7.4077e-05.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 16/20: \n",
            "Train Acc 78.2154%\t Train Loss 0.4866\t Learning Rate 0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc 75.0000%\t Val Loss 0.5060\n",
            "Adjusting learning rate of group 0 to 4.8650e-05.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 17/20: \n",
            "Train Acc 78.8384%\t Train Loss 0.4833\t Learning Rate 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc 74.4792%\t Val Loss 0.5093\n",
            "Adjusting learning rate of group 0 to 2.8194e-05.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 18/20: \n",
            "Train Acc 78.6777%\t Train Loss 0.4806\t Learning Rate 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc 75.0000%\t Val Loss 0.5058\n",
            "Adjusting learning rate of group 0 to 1.3211e-05.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 19/20: \n",
            "Train Acc 79.0394%\t Train Loss 0.4790\t Learning Rate 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc 74.7396%\t Val Loss 0.5092\n",
            "Adjusting learning rate of group 0 to 4.0718e-06.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 20/20: \n",
            "Train Acc 78.8284%\t Train Loss 0.4800\t Learning Rate 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                                "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc 74.4792%\t Val Loss 0.5091\n",
            "Adjusting learning rate of group 0 to 1.0000e-06.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(val_list)"
      ],
      "metadata": {
        "id": "ppn5LPIkS664",
        "outputId": "f04b016a-b274-4915-c05f-f57b89dcf5f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[72.65625, 71.875, 71.09375, 71.09375, 73.17708333333333, 76.82291666666667, 77.34375, 75.26041666666667, 75.0, 76.04166666666667, 75.78125, 76.82291666666667, 76.30208333333333, 75.52083333333333, 75.26041666666667, 75.0, 74.47916666666667, 75.0, 74.73958333333333, 74.47916666666667]\n"
          ]
        }
      ]
    }
  ]
}